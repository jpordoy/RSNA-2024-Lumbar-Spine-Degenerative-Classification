{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30762,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic Libraries\nimport os\nimport shutil\nimport random\nimport numpy as np\nimport pandas as pd\n\n# Image Processing\nimport cv2\nfrom PIL import Image, ImageEnhance\nfrom skimage.util import random_noise\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\n# Scikit-learn for Model Preparation\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\n\n# Additional Libraries for Image Handling and File Operations\nimport glob\nfrom glob import glob\nimport matplotlib.image as mpimg\nimport pydicom\n\n# TensorFlow and Keras for Deep Learning\nimport tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Attention, Add, Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.callbacks import ModelCheckpoint\n\nprint(\"Imports Complete\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-23T11:52:03.795794Z","iopub.execute_input":"2024-09-23T11:52:03.796858Z","iopub.status.idle":"2024-09-23T11:52:03.808321Z","shell.execute_reply.started":"2024-09-23T11:52:03.796799Z","shell.execute_reply":"2024-09-23T11:52:03.807308Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Imports Complete\n","output_type":"stream"}]},{"cell_type":"code","source":"# Path to the input and output directories\ntrain_input_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/'\ntest_input_path= '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images/'\n\ndf_train = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\ndf_train_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\ndf_label_coord = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\ndf_test_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n\n# Output Paths\noutput_path_train_dir = '/kaggle/working/train_images'\noutput_path_augmented_dir ='/kaggle/working/augmented_images'","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:52:03.899912Z","iopub.execute_input":"2024-09-23T11:52:03.900236Z","iopub.status.idle":"2024-09-23T11:52:04.004812Z","shell.execute_reply.started":"2024-09-23T11:52:03.900203Z","shell.execute_reply":"2024-09-23T11:52:04.003792Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# Create image paths\ndf_label_coord['image_path'] = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/\" + \\\n                               df_label_coord['study_id'].astype(str) + \"/\" + \\\n                               df_label_coord['series_id'].astype(str) + \"/\" + \\\n                               df_label_coord['instance_number'].astype(str) + \".dcm\"\n\n# Melt the df_train DataFrame\ndf_train_melted = df_train.melt(id_vars=['study_id'], var_name='condition_level', value_name='severity')\n\n# Split 'condition_level' to extract 'condition' and 'level'\ndf_train_melted[['conditions', 'level']] = df_train_melted['condition_level'].str.rsplit('_', n=2, expand=True).iloc[:, 1:]\ndf_train_melted['condition'] = df_train_melted['condition_level'].apply(lambda x: '_'.join(x.split('_')[:-2])).str.replace(\"_\", \" \").str.title()\ndf_train_melted['level'] = df_train_melted['conditions'].str.upper() + \"/\" + df_train_melted['level'].str.upper()\n\n# Drop the original 'condition_level' column\ndf_train_melted = df_train_melted.drop(columns=['condition_level', 'conditions'])\n\n# Merge DataFrames on 'study_id', 'level', and 'condition'\ndf_final = pd.merge(df_label_coord, df_train_melted, on=['study_id', 'level', 'condition'], how='inner')\n\n# Ensure the 'series_description' column exists before trying to reorder\nif 'series_description' in df_train_series_descriptions.columns:\n    # Merge df_final with df_train_series_descriptions on 'study_id' and 'series_id'\n    df_final_filtered = pd.merge(df_final, df_train_series_descriptions[['study_id', 'series_id', 'series_description']],\n                                 on=['study_id', 'series_id'], how='left')\n\n    # Reorder columns to place 'series_description' immediately after 'series_id'\n    columns_order = ['study_id', 'series_id', 'series_description', 'instance_number', 'condition', 'level', 'x', 'y', 'image_path', 'severity']\n    \n    # Ensure that 'series_description' exists in the DataFrame before reordering columns\n    if 'series_description' in df_final_filtered.columns:\n        df_final_filtered = df_final_filtered[columns_order]\n    else:\n        print(\"Warning: 'series_description' column not found after merging.\")\nelse:\n    print(\"Warning: 'series_description' column not found in the input data.\")\n    \ndf_final_filtered.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:52:04.043672Z","iopub.execute_input":"2024-09-23T11:52:04.044088Z","iopub.status.idle":"2024-09-23T11:52:04.495277Z","shell.execute_reply.started":"2024-09-23T11:52:04.044035Z","shell.execute_reply":"2024-09-23T11:52:04.494251Z"},"trusted":true},"execution_count":46,"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"   study_id  series_id series_description  instance_number  \\\n0   4003253  702807833   Sagittal T2/STIR                8   \n1   4003253  702807833   Sagittal T2/STIR                8   \n2   4003253  702807833   Sagittal T2/STIR                8   \n3   4003253  702807833   Sagittal T2/STIR                8   \n4   4003253  702807833   Sagittal T2/STIR                8   \n\n               condition  level           x           y  \\\n0  Spinal Canal Stenosis  L1/L2  322.831858  227.964602   \n1  Spinal Canal Stenosis  L2/L3  320.571429  295.714286   \n2  Spinal Canal Stenosis  L3/L4  323.030303  371.818182   \n3  Spinal Canal Stenosis  L4/L5  335.292035  427.327434   \n4  Spinal Canal Stenosis  L5/S1  353.415929  483.964602   \n\n                                          image_path     severity  \n0  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild  \n1  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild  \n2  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild  \n3  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild  \n4  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>series_description</th>\n      <th>instance_number</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>x</th>\n      <th>y</th>\n      <th>image_path</th>\n      <th>severity</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L1/L2</td>\n      <td>322.831858</td>\n      <td>227.964602</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L2/L3</td>\n      <td>320.571429</td>\n      <td>295.714286</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L3/L4</td>\n      <td>323.030303</td>\n      <td>371.818182</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L4/L5</td>\n      <td>335.292035</td>\n      <td>427.327434</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4003253</td>\n      <td>702807833</td>\n      <td>Sagittal T2/STIR</td>\n      <td>8</td>\n      <td>Spinal Canal Stenosis</td>\n      <td>L5/S1</td>\n      <td>353.415929</td>\n      <td>483.964602</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Create the row_id column\ndf_final_filtered['row_id'] = (\n    df_final_filtered['study_id'].astype(str) + '_' +\n    df_final_filtered['condition'].str.lower().str.replace(' ', '_') + '_' +\n    df_final_filtered['level'].str.lower().str.replace('/', '_')\n)\n\ndf_final_filtered.sample()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:52:04.497642Z","iopub.execute_input":"2024-09-23T11:52:04.498118Z","iopub.status.idle":"2024-09-23T11:52:04.630931Z","shell.execute_reply.started":"2024-09-23T11:52:04.498067Z","shell.execute_reply":"2024-09-23T11:52:04.629969Z"},"trusted":true},"execution_count":47,"outputs":[{"execution_count":47,"output_type":"execute_result","data":{"text/plain":"       study_id  series_id series_description  instance_number  \\\n4899  425970461  201607168           Axial T2               12   \n\n                        condition  level          x           y  \\\n4899  Right Subarticular Stenosis  L3/L4  164.71137  194.798834   \n\n                                             image_path     severity  \\\n4899  /kaggle/input/rsna-2024-lumbar-spine-degenerat...  Normal/Mild   \n\n                                           row_id  \n4899  425970461_right_subarticular_stenosis_l3_l4  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>study_id</th>\n      <th>series_id</th>\n      <th>series_description</th>\n      <th>instance_number</th>\n      <th>condition</th>\n      <th>level</th>\n      <th>x</th>\n      <th>y</th>\n      <th>image_path</th>\n      <th>severity</th>\n      <th>row_id</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>4899</th>\n      <td>425970461</td>\n      <td>201607168</td>\n      <td>Axial T2</td>\n      <td>12</td>\n      <td>Right Subarticular Stenosis</td>\n      <td>L3/L4</td>\n      <td>164.71137</td>\n      <td>194.798834</td>\n      <td>/kaggle/input/rsna-2024-lumbar-spine-degenerat...</td>\n      <td>Normal/Mild</td>\n      <td>425970461_right_subarticular_stenosis_l3_l4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# Function to convert DICOM pixel array to PNG\ndef readdcm_writepng_image(src_dicom_pixelarray, dest_path_png):\n    src_dicom_pixelarray = np.array(src_dicom_pixelarray)\n    standardized_image_data = ((src_dicom_pixelarray - src_dicom_pixelarray.min()) / \n                               (src_dicom_pixelarray.max() - src_dicom_pixelarray.min() + 1e-10)) * 255\n    standardized_image_data = standardized_image_data.astype(np.uint8)\n    final_image_to_png = cv2.resize(standardized_image_data, (320, 320), interpolation=cv2.INTER_CUBIC)\n    cv2.imwrite(dest_path_png, final_image_to_png)\n\n# Remove previous output directory for fresh writing\nif os.path.isdir(output_path_train_dir):\n    shutil.rmtree(output_path_train_dir)\n\n# Drop duplicates based on 'image_path' to ensure each image is converted only once\nunique_images_df = df_final_filtered.drop_duplicates(subset='image_path')\n\n# Create a new DataFrame to store paths to the converted images\ndf_train_images_png = pd.DataFrame(columns=df_final_filtered.columns)\n\n# Convert only unique labeled images\nfor index, row in tqdm(unique_images_df.iterrows(), total=len(unique_images_df)):\n    study_id = row['study_id']\n    # Apply the replacement to series_description\n    series_description = row['series_description'].replace(' ', '_').replace('/', '_')\n    instance_number = row['instance_number']\n    \n    # Construct the destination path for the PNG file\n    dest_path = f'{output_path_train_dir}/{study_id}/{series_description}/{instance_number}.png'\n    \n    # Ensure directory exists\n    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n    \n    # Read the DICOM image and convert it to PNG\n    dicom_image = pydicom.dcmread(row['image_path'])\n    readdcm_writepng_image(dicom_image.pixel_array, dest_path)\n    \n    # Copy the row and update the image path to the new PNG path\n    new_row = row.copy()\n    new_row['image_path'] = dest_path\n    \n    # Replace series_description in the new_row DataFrame\n    new_row['series_description'] = series_description\n    \n    # Append the new row to the new DataFrame using pd.concat\n    df_train_images_png = pd.concat([df_train_images_png, pd.DataFrame([new_row])], ignore_index=True)\n\nprint(\"Conversion to PNG completed.\")\n\n# Save the new DataFrame to a CSV file (optional)\ndf_train_images_png.to_csv('/kaggle/working/df_png_paths.csv', index=False)\n\nprint(\"Dataframe saved\")\ndf_train_images_png.sample()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:52:04.632122Z","iopub.execute_input":"2024-09-23T11:52:04.632464Z","iopub.status.idle":"2024-09-23T11:54:33.132475Z","shell.execute_reply.started":"2024-09-23T11:52:04.632429Z","shell.execute_reply":"2024-09-23T11:54:33.129369Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stderr","text":"  0%|          | 0/24546 [00:00<?, ?it/s]/tmp/ipykernel_36/4124105440.py:45: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n  df_train_images_png = pd.concat([df_train_images_png, pd.DataFrame([new_row])], ignore_index=True)\n 30%|███       | 7465/24546 [02:26<05:34, 51.12it/s]\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[48], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m     new_row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseries_description\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m series_description\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Append the new row to the new DataFrame using pd.concat\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m     df_train_images_png \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mdf_train_images_png\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnew_row\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConversion to PNG completed.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# Save the new DataFrame to a CSV file (optional)\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:395\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    380\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    382\u001b[0m op \u001b[38;5;241m=\u001b[39m _Concatenator(\n\u001b[1;32m    383\u001b[0m     objs,\n\u001b[1;32m    384\u001b[0m     axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    392\u001b[0m     sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    393\u001b[0m )\n\u001b[0;32m--> 395\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/reshape/concat.py:684\u001b[0m, in \u001b[0;36m_Concatenator.get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    680\u001b[0m             indexers[ax] \u001b[38;5;241m=\u001b[39m obj_labels\u001b[38;5;241m.\u001b[39mget_indexer(new_labels)\n\u001b[1;32m    682\u001b[0m     mgrs_indexers\u001b[38;5;241m.\u001b[39mappend((obj\u001b[38;5;241m.\u001b[39m_mgr, indexers))\n\u001b[0;32m--> 684\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mconcatenate_managers\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmgrs_indexers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnew_axes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconcat_axis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbm_axis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcopy \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    688\u001b[0m     new_data\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/concat.py:193\u001b[0m, in \u001b[0;36mconcatenate_managers\u001b[0;34m(mgrs_indexers, axes, concat_axis, copy)\u001b[0m\n\u001b[1;32m    190\u001b[0m     fastpath \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m fastpath:\n\u001b[0;32m--> 193\u001b[0m     b \u001b[38;5;241m=\u001b[39m \u001b[43mblk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmake_block_same_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    195\u001b[0m     b \u001b[38;5;241m=\u001b[39m new_block_2d(values, placement\u001b[38;5;241m=\u001b[39mplacement)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/pandas/core/internals/blocks.py:306\u001b[0m, in \u001b[0;36mBlock.make_block_same_class\u001b[0;34m(self, values, placement, refs)\u001b[0m\n\u001b[1;32m    303\u001b[0m     placement \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr_locs\n\u001b[1;32m    305\u001b[0m \u001b[38;5;66;03m# We assume maybe_coerce_values has already been called\u001b[39;00m\n\u001b[0;32m--> 306\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mplacement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mplacement\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mndim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mndim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"from concurrent.futures import ThreadPoolExecutor\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast,\n    ColorJitter, GridDistortion, RandomGamma, GaussNoise, Compose,\n    CLAHE, Solarize, Posterize, ShiftScaleRotate, ElasticTransform,\n    ToGray, HueSaturationValue\n)\n\n# Step 1: Initialise Paths\ndf_converted_data = pd.read_csv(\"/kaggle/working/df_png_paths.csv\")\noutput_images_dir = '/kaggle/working/augmented_images'\ncsv_output_path = '/kaggle/working/df_augmented_final.csv'\n\n# Ensure output directory exists\nos.makedirs(output_images_dir, exist_ok=True)\n\n# Step 2: Assume df_png_paths is already defined with the necessary data\n# You need to format the series_description\ndf_augmented = df_train_images_png.copy()\ndf_augmented['series_description'] = df_augmented['series_description'].str.replace(r'[ /]', '_', regex=True)\n\n# Step 3: Define color map augmentation functions\ndef apply_color_map(image, colormap):\n    return cv2.applyColorMap(image, colormap)\n\n# Step 4: Define augmentation techniques\nalbumentations_augmentations = [\n    Compose([Rotate(limit=90), HorizontalFlip()]),\n    Compose([Rotate(limit=180)]),\n    Compose([Rotate(limit=270), HorizontalFlip()]),\n    Compose([ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)]),\n    Compose([GaussNoise(), VerticalFlip()]),\n    Compose([GridDistortion()]),\n    Compose([ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15)]),\n    Compose([ElasticTransform(alpha=1, sigma=50, alpha_affine=None)]),  # Updated line\n    Compose([CLAHE(), HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20)]),\n    Compose([Solarize(threshold=128.0), Posterize(num_bits=4)]),\n    Compose([ToGray()])\n]\n\ncolor_map_augmentations = [\n    (cv2.COLORMAP_VIRIDIS, 'viridis'),\n    (cv2.COLORMAP_PLASMA, 'plasma'),\n    (cv2.COLORMAP_INFERNO, 'inferno'),\n    (cv2.COLORMAP_MAGMA, 'magma'),\n]\n\n# Combine all augmentations into one list\nall_augmentations = albumentations_augmentations + color_map_augmentations\n\n# Define how many times to augment each image for Moderate and Severe classes\nnum_augmentations_per_image_severe = 10 # Augment each 'Severe' image 6 times\nnum_augmentations_per_image_moderate = 4  # Augment each 'Moderate' image 1 time\n\ndef augment_image(row):\n    image_path = row['image_path']\n    image = cv2.imread(image_path)  # Load the image using OpenCV\n\n    # Check if the image was loaded successfully\n    if image is None:\n        print(f\"Warning: Unable to load image at path: {image_path}\")\n        return []  # Return an empty list if the image could not be loaded\n\n    coords = [row['x'], row['y']]  # Extract coordinates\n    augmented_images = []  # Store augmented images for this row\n    image_height, image_width = image.shape[:2]\n\n    # Determine the number of augmentations based on severity\n    if row['severity'] == 'Severe':\n        num_augmentations = num_augmentations_per_image_severe\n    elif row['severity'] == 'Moderate':\n        num_augmentations = num_augmentations_per_image_moderate\n    else:\n        return []  # Skip if severity is not 'Moderate' or 'Severe'\n\n    for _ in range(num_augmentations):\n        # Choose an augmentation\n        aug_index = np.random.choice(len(all_augmentations))\n        aug = all_augmentations[aug_index]\n\n        try:\n            if isinstance(aug, tuple):\n                # Apply the color map augmentation\n                colormap, name = aug\n                image_aug = apply_color_map(image, colormap)\n                aug_name = name  # Use the color map name directly\n            else:\n                # Apply the Albumentations augmentation\n                augmented = aug(image=image)\n                image_aug = augmented['image']\n\n                # Get the augmentation names\n                aug_name = '_'.join([type(t).__name__ for t in aug.transforms])\n\n                # Update coordinates based on the applied transformations\n                for t in aug.transforms:\n                    if isinstance(t, HorizontalFlip):\n                        coords[0] = image_width - coords[0]\n                    if isinstance(t, VerticalFlip):\n                        coords[1] = image_height - coords[1]\n                    if isinstance(t, Rotate):\n                        angle = t.limit if isinstance(t.limit, (int, float)) else t.limit[1]\n                        if angle == 90:\n                            coords = [coords[1], image_width - coords[0]]\n                        elif angle == 180:\n                            coords = [image_width - coords[0], image_height - coords[1]]\n                        elif angle == 270:\n                            coords = [image_height - coords[1], coords[0]]\n\n            # Create subfolder structure\n            study_id = row['study_id']\n            series_id = row['series_id']\n            series_description = row['series_description'].replace(' ', '_')  # Replace spaces with underscores\n            output_subfolder = os.path.join(output_images_dir, str(study_id), series_description)\n            os.makedirs(output_subfolder, exist_ok=True)\n\n            # Generate new file name with the augmentation name and instance number\n            instance_number = row['instance_number']\n            augmented_image_path = os.path.join(output_subfolder, f\"{aug_name}_{instance_number}.png\")\n\n            # Save the augmented image\n            cv2.imwrite(augmented_image_path, image_aug)\n\n            augmented_images.append({\n                'study_id': study_id,\n                'series_id': series_id,\n                'series_description': series_description,\n                'instance_number': instance_number,\n                'x': coords[0],\n                'y': coords[1],\n                'condition': row['condition'],\n                'level': row['level'],\n                'image_path': augmented_image_path,\n                'severity': row['severity']\n            })\n        except Exception as e:\n            print(f\"Error processing image {image_path}: {e}\")\n\n    return augmented_images\n\n\n# Step 7: Filter only Moderate and Severe classes for augmentation\ndf_filtered = df_augmented[df_augmented['severity'].isin(['Moderate', 'Severe'])]\n\n# Step 8: Use parallel processing to augment images\naugmented_data = []\n\nwith ThreadPoolExecutor() as executor:\n    results = list(tqdm(executor.map(augment_image, [row for _, row in df_filtered.iterrows()]), total=len(df_filtered)))\n\n# Flatten the results and filter out None values\naugmented_data = [item for sublist in results for item in sublist if item is not None]\n\n# Step 9: Collect the results into a DataFrame\ndf_augmented_final = pd.DataFrame(augmented_data)\n\n# Save the augmented DataFrame to a CSV file\ndf_augmented_final.to_csv(csv_output_path, index=False)\n\nprint(f\"Total processed images: {len(augmented_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.133469Z","iopub.status.idle":"2024-09-23T11:54:33.133829Z","shell.execute_reply.started":"2024-09-23T11:54:33.133653Z","shell.execute_reply":"2024-09-23T11:54:33.133671Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# read data\ntrain_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/'\ntrain_desc  = pd.read_csv(train_path + 'train_series_descriptions.csv')\ntest_desc   = pd.read_csv(train_path + 'test_series_descriptions.csv')\ntest_desc['series_description'] = test_desc['series_description'].str.replace(r'[ /]', '_', regex=True)\ntest_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.134893Z","iopub.status.idle":"2024-09-23T11:54:33.135344Z","shell.execute_reply.started":"2024-09-23T11:54:33.135129Z","shell.execute_reply":"2024-09-23T11:54:33.135150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\noutput_path = '/kaggle/working/test_images/'\n\n# Function to convert DICOM pixel array to PNG\ndef readdcm_writepng_image(src_dicom_pixelarray, dest_path_png):\n    src_dicom_pixelarray = np.array(src_dicom_pixelarray)\n    standardized_image_data = ((src_dicom_pixelarray - src_dicom_pixelarray.min()) / \n                               (src_dicom_pixelarray.max() - src_dicom_pixelarray.min() + 1e-10)) * 255\n    standardized_image_data = standardized_image_data.astype(np.uint8)\n    final_image_to_png = cv2.resize(standardized_image_data, (320, 320), interpolation=cv2.INTER_CUBIC)\n    cv2.imwrite(dest_path_png, final_image_to_png)\n\n# Remove previous output directory for fresh writing\nif os.path.isdir(output_path):\n    shutil.rmtree(output_path)\n\n\n# Iterate over the test data\nfor idx, row in tqdm(test_desc.iterrows(), total=len(test_desc)):\n    study_id = row['study_id']\n    series_id = row['series_id']\n    series_desc = row['series_description'].replace(' ', '_').replace('/', '_')\n    \n    # Define the new directory structure for PNGs\n    series_output_dir = f'{output_path}/{study_id}/{series_desc}'\n    os.makedirs(series_output_dir, exist_ok=True)\n    \n    # Get all DICOM files in this series\n    series_dicom_dir = f'{test_input_path}/{study_id}/{series_id}'\n    dicom_files = glob(f'{series_dicom_dir}/*.dcm')\n    \n    # Convert each DICOM file to PNG\n    for dicom_file in dicom_files:\n        dicom_image = pydicom.dcmread(dicom_file)\n        image_filename = os.path.splitext(os.path.basename(dicom_file))[0]  # Use SOPInstanceUID for naming\n        image_dicom_pixelarray = dicom_image.pixel_array\n        \n        dest_path = f'{series_output_dir}/{image_filename}.png'\n        readdcm_writepng_image(image_dicom_pixelarray, dest_path)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.136318Z","iopub.status.idle":"2024-09-23T11:54:33.136776Z","shell.execute_reply.started":"2024-09-23T11:54:33.136538Z","shell.execute_reply":"2024-09-23T11:54:33.136564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define the base path for test images\nbase_path = '/kaggle/working/test_images'\n\n# Function to get image paths for a series\ndef get_image_paths(row):\n    series_path = os.path.join(base_path, str(row['study_id']), str(row['series_description']))\n    if os.path.exists(series_path):\n        return [os.path.join(series_path, f) for f in os.listdir(series_path) if os.path.isfile(os.path.join(series_path, f))]\n    return []\n\n# Mapping of series_description to conditions\ncondition_mapping = {\n    'Sagittal_T1': {'left': 'left_neural_foraminal_narrowing', 'right': 'right_neural_foraminal_narrowing'},\n    'Axial_T2': {'left': 'left_subarticular_stenosis', 'right': 'right_subarticular_stenosis'},\n    'Sagittal_T2_STIR': 'spinal_canal_stenosis'\n}\n\n# Create a list to store the expanded rows\nexpanded_rows = []\n\n# Expand the dataframe by adding new rows for each file path\nfor index, row in test_desc.iterrows():\n    image_paths = get_image_paths(row)\n    conditions = condition_mapping.get(row['series_description'], {})\n    if isinstance(conditions, str):  # Single condition\n        conditions = {'left': conditions, 'right': conditions}\n    for side, condition in conditions.items():\n        for image_path in image_paths:\n            expanded_rows.append({\n                'study_id': row['study_id'],\n                'series_id': row['series_id'],\n                'series_description': row['series_description'],\n                'image_path': image_path,\n                'condition': condition,\n                'row_id': f\"{row['study_id']}_{condition}\"\n            })\n\n# Create a new dataframe from the expanded rows\nexpanded_test_desc = pd.DataFrame(expanded_rows)\n\n# Extracting the instance number from the image_path\nexpanded_test_desc['instance_number'] = expanded_test_desc['image_path'].apply(\n    lambda x: int(os.path.splitext(os.path.basename(x))[0])  # Get the filename without extension\n)\n\nlevels = ['l1_l2', 'l2_l3', 'l3_l4', 'l4_l5', 'l5_s1']\n\n# Function to update row_id with levels\ndef update_row_id(row, levels):\n    level = levels[row.name % len(levels)]\n    return f\"{row['study_id']}_{row['condition']}_{level}\"\n\n# Update row_id in expanded_test_desc to include levels\nexpanded_test_desc['row_id'] = expanded_test_desc.apply(lambda row: update_row_id(row, levels), axis=1)\n\n# Display the resulting dataframe\nexpanded_test_desc.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.138028Z","iopub.status.idle":"2024-09-23T11:54:33.138532Z","shell.execute_reply.started":"2024-09-23T11:54:33.138283Z","shell.execute_reply":"2024-09-23T11:54:33.138307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with severity equal to 0 or NaN\ndf_final_filtered_cleaned = df_train_images_png[(df_train_images_png['severity'] != 0) & (df_train_images_png['severity'].notna())]\ndf_augmented_cleaned = df_augmented_final[(df_augmented_final['severity'] != 0) & (df_augmented_final['severity'].notna())]\n\n# Display the resulting DataFrame\nprint(f\"Data after removing rows with severity 0 or NaN: {df_final_filtered_cleaned.shape[0]} samples\")\nprint(f\"Data after removing rows with severity 0 or NaN: {df_augmented_cleaned.shape[0]} samples\")\n\n# Concatenate the cleaned DataFrames\ndf_concat = pd.concat([df_final_filtered_cleaned, df_augmented_cleaned], ignore_index=True)\n\n# Check the class distribution after balancing\nprint(df_concat[\"severity\"].value_counts())","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.140793Z","iopub.status.idle":"2024-09-23T11:54:33.141303Z","shell.execute_reply.started":"2024-09-23T11:54:33.141019Z","shell.execute_reply":"2024-09-23T11:54:33.141044Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# List to store paths of corrupted files\ncorrupted_files = []\n\n# Check each image in the dataset\nfor index, row in df_concat.iterrows():\n    img_path = row['image_path']\n    try:\n        # Try to open the image file\n        img = Image.open(img_path)\n        img.verify()  # Verify that it is a valid image\n    except (IOError, SyntaxError) as e:\n        corrupted_files.append(img_path)\n\n# Remove corrupted files from the DataFrame\ndf_concat_cleaned = df_concat[~df_concat['image_path'].isin(corrupted_files)]\n\n# Create the final augmented DataFrame with cleaned data\ndf_concat = df_concat_cleaned.copy()\n\n# Print the number of corrupted files found and removed\nprint(f\"Number of corrupted files removed: {len(corrupted_files)}\")\n\n# Print the number of valid rows in the final DataFrame\nprint(f\"Number of valid rows in the final DataFrame: {df_concat.shape[0]}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.142314Z","iopub.status.idle":"2024-09-23T11:54:33.142669Z","shell.execute_reply.started":"2024-09-23T11:54:33.142491Z","shell.execute_reply":"2024-09-23T11:54:33.142510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Assuming df_dataset is your original DataFrame with columns: \n# 'series_description', 'condition', 'level', 'severity', and others.\n\n# Function to perform oversampling on a full DataFrame while considering series_description and severity\ndef oversample_by_severity(df):\n    # Create the feature set (X) and target (y)\n    X = df.drop(columns=['severity'])  # Keep all other columns except 'severity'\n    y = df['severity']  # Target is the 'severity' column\n    \n    # Apply RandomOverSampler based on the severity imbalance\n    ros = RandomOverSampler(sampling_strategy='auto')  # Automatically balance all severity classes\n    X_resampled, y_resampled = ros.fit_resample(X, y)\n    \n    # Combine resampled X and y back into a DataFrame\n    df_resampled = pd.DataFrame(X_resampled, columns=X.columns)  # Features\n    df_resampled['severity'] = y_resampled  # Add back the severity column\n    \n    return df_resampled\n\n# Initialize an empty list to store oversampled data\noversampled_dfs = []\n\n# Iterate over each series_description group\nfor series_description, group_df in df_concat.groupby('series_description'):\n    print(f\"Oversampling for series_description: {series_description}\")\n    \n    # Perform oversampling for the current group based on severity\n    df_resampled = oversample_by_severity(group_df)\n    \n    # Add back the series_description column to the resampled DataFrame\n    df_resampled['series_description'] = series_description\n    \n    # Append the resampled DataFrame to the list\n    oversampled_dfs.append(df_resampled)\n\n# Concatenate all oversampled DataFrames into one\ndf_oversampled = pd.concat(oversampled_dfs, ignore_index=True)\n\n# Now df_oversampled contains the oversampled data, balanced by severity for each series_description\nprint(f\"Oversampled dataset size: {df_oversampled.shape}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:54:33.144523Z","iopub.status.idle":"2024-09-23T11:54:33.145006Z","shell.execute_reply.started":"2024-09-23T11:54:33.144753Z","shell.execute_reply":"2024-09-23T11:54:33.144780Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras import layers, models\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Define your CNN model with customizable parameters for each convolutional layer\ndef create_cnn_model(input_shape, num_classes, dropout_rate=0.25, learning_rate=0.0001, \n                     use_batch_norm=False, use_attention=False, \n                     conv_filters=[32, 64, 128], dense_units=128):\n    model = models.Sequential()\n    \n    # First convolutional block\n    model.add(layers.Conv2D(conv_filters[0], (3, 3), activation='relu', input_shape=input_shape))\n    if use_batch_norm:\n        model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(dropout_rate))\n\n    # Second convolutional block\n    model.add(layers.Conv2D(conv_filters[1], (3, 3), activation='relu'))\n    if use_batch_norm:\n        model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(dropout_rate))\n\n    # Third convolutional block\n    model.add(layers.Conv2D(conv_filters[2], (3, 3), activation='relu'))\n    if use_batch_norm:\n        model.add(layers.BatchNormalization())\n    model.add(layers.MaxPooling2D((2, 2)))\n    model.add(layers.Dropout(dropout_rate))\n\n    # Attention Layer (example implementation)\n    if use_attention:\n        model.add(layers.GlobalAveragePooling2D())\n        model.add(layers.Dense(128, activation='relu'))\n        model.add(layers.Dense(num_classes, activation='softmax'))\n\n    # Fully connected layers\n    model.add(layers.Flatten())\n    model.add(layers.Dense(dense_units, activation='relu'))\n    if use_batch_norm:\n        model.add(layers.BatchNormalization())\n\n    # Output layer\n    model.add(layers.Dense(num_classes, activation='softmax'))\n    \n    # Compile the model with a specified optimizer\n    model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=learning_rate),\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])    \n    return model\n\n# Set parameters\nimage_size = (320, 320)  # Target size for images\nbatch_size = 64\nepochs = 10\ninput_shape = (*image_size, 3)  # Assuming RGB images\nnum_classes = 3  # Severity has 3 categories\n\n# Define custom hyperparameters for each series\nhyperparameters = {\n    'Series_1': {'dropout_rate': 0.2, 'learning_rate': 0.0001, 'use_batch_norm': True, 'use_attention': True, 'conv_filters': [32, 64, 128], 'dense_units': 128},\n    'Series_2': {'dropout_rate': 0.3, 'learning_rate': 0.0005, 'use_batch_norm': False, 'use_attention': True, 'conv_filters': [64, 128, 64], 'dense_units': 64},\n    'Series_3': {'dropout_rate': 0.4, 'learning_rate': 0.001, 'use_batch_norm': True, 'use_attention': False, 'conv_filters': [128, 64, 32], 'dense_units': 256},\n    # Add more series and their hyperparameters as needed\n}\n\n# Assuming df_dataset is your DataFrame containing the dataset with 'severity' and 'series_description'\n\n# Get unique series_descriptions from the DataFrame\nseries_descriptions = df_oversampled['series_description'].unique()\n\n# Iterate through each series_description\nfor series in series_descriptions:\n    print(f\"\\nTraining model for series description: {series}\")\n    \n    # Filter the DataFrame for the current series_description\n    series_df = df_oversampled[df_oversampled['series_description'] == series]\n    \n    # Ensure we have 3 classes in the 'severity' column\n    assert series_df['severity'].nunique() == 3, \"The 'severity' column must have exactly 3 classes\"\n    \n    # Split the data into train, validation, and test sets\n    train_df, test_df = train_test_split(series_df, test_size=0.25, stratify=series_df['severity'])\n    train_df, val_df = train_test_split(train_df, test_size=0.35, stratify=train_df['severity'])\n\n    # ImageDataGenerator setup\n    datagen = ImageDataGenerator(rescale=1.0/255)\n\n    # Create ImageDataGenerators for train, validation, and test sets\n    train_generator = datagen.flow_from_dataframe(\n        dataframe=train_df,\n        x_col='image_path',\n        y_col='severity',\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True\n    )\n\n    val_generator = datagen.flow_from_dataframe(\n        dataframe=val_df,\n        x_col='image_path',\n        y_col='severity',\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    test_generator = datagen.flow_from_dataframe(\n        dataframe=test_df,\n        x_col='image_path',\n        y_col='severity',\n        target_size=image_size,\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=False\n    )\n\n    # Get hyperparameters for the current series\n    series_hyperparams = hyperparameters.get(series, {'dropout_rate': 0.25, 'learning_rate': 0.0001, 'use_batch_norm': False, 'use_attention': False, 'conv_filters': [32, 64, 128], 'dense_units': 128})\n    \n    # Create CNN model for the current series_description with custom hyperparameters\n    model = create_cnn_model(input_shape, num_classes, \n                             dropout_rate=series_hyperparams['dropout_rate'], \n                             learning_rate=series_hyperparams['learning_rate'],\n                             use_batch_norm=series_hyperparams['use_batch_norm'],\n                             use_attention=series_hyperparams['use_attention'],\n                             conv_filters=series_hyperparams['conv_filters'],\n                             dense_units=series_hyperparams['dense_units'])\n\n    # Train the model\n    history = model.fit(\n        train_generator,\n        validation_data=val_generator,\n        epochs=epochs,\n        verbose=1\n    )\n\n    # Save the model after training\n    model.save(f\"/kaggle/working/{series}_model.h5\")\n\n    # Evaluate the model on the test set\n    test_loss, test_acc = model.evaluate(test_generator)\n    print(f\"Test Accuracy for {series}: {test_acc:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-23T11:57:53.408241Z","iopub.execute_input":"2024-09-23T11:57:53.408651Z","iopub.status.idle":"2024-09-23T12:33:52.183208Z","shell.execute_reply.started":"2024-09-23T11:57:53.408613Z","shell.execute_reply":"2024-09-23T12:33:52.182141Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"\nTraining model for series description: Axial_T2\nFound 14657 validated image filenames belonging to 3 classes.\nFound 7925 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 6369 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3397 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"Found 7589 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3194 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n2024-09-23 11:58:10.242362: E external/local_xla/xla/service/slow_operation_alarm.cc:65] Trying algorithm eng0{} for conv (f32[64,32,159,159]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,157,157]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n2024-09-23 11:58:10.413124: E external/local_xla/xla/service/slow_operation_alarm.cc:133] The operation took 1.170853897s\nTrying algorithm eng0{} for conv (f32[64,32,159,159]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,64,157,157]{3,2,1,0}, f32[64,32,3,3]{3,2,1,0}), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBackwardInput\", backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0}} is taking a while...\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 560ms/step - accuracy: 0.4587 - loss: 1.2527 - val_accuracy: 0.5587 - val_loss: 0.9343\nEpoch 2/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 512ms/step - accuracy: 0.5589 - loss: 0.8492 - val_accuracy: 0.5585 - val_loss: 0.9235\nEpoch 3/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 508ms/step - accuracy: 0.6170 - loss: 0.7740 - val_accuracy: 0.5804 - val_loss: 0.8845\nEpoch 4/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 510ms/step - accuracy: 0.6689 - loss: 0.7023 - val_accuracy: 0.6268 - val_loss: 0.8092\nEpoch 5/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 510ms/step - accuracy: 0.6943 - loss: 0.6574 - val_accuracy: 0.6215 - val_loss: 0.7969\nEpoch 6/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 514ms/step - accuracy: 0.7359 - loss: 0.5871 - val_accuracy: 0.6254 - val_loss: 0.7963\nEpoch 7/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 513ms/step - accuracy: 0.7804 - loss: 0.5181 - val_accuracy: 0.7118 - val_loss: 0.6538\nEpoch 8/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m120s\u001b[0m 511ms/step - accuracy: 0.8147 - loss: 0.4444 - val_accuracy: 0.7430 - val_loss: 0.6219\nEpoch 9/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 508ms/step - accuracy: 0.8565 - loss: 0.3618 - val_accuracy: 0.7788 - val_loss: 0.5679\nEpoch 10/10\n\u001b[1m230/230\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m119s\u001b[0m 509ms/step - accuracy: 0.8899 - loss: 0.2922 - val_accuracy: 0.7991 - val_loss: 0.5393\n\u001b[1m119/119\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 374ms/step - accuracy: 0.8085 - loss: 0.5308\nTest Accuracy for Axial_T2: 0.8052\n\nTraining model for series description: Sagittal_T1\nFound 7237 validated image filenames belonging to 3 classes.\nFound 3872 validated image filenames belonging to 3 classes.\nFound 3653 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 3010 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1646 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 1603 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 582ms/step - accuracy: 0.4278 - loss: 1.1893 - val_accuracy: 0.4835 - val_loss: 1.0055\nEpoch 2/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 504ms/step - accuracy: 0.4800 - loss: 0.9477 - val_accuracy: 0.4910 - val_loss: 0.9642\nEpoch 3/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 503ms/step - accuracy: 0.5198 - loss: 0.9116 - val_accuracy: 0.5212 - val_loss: 0.9538\nEpoch 4/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 504ms/step - accuracy: 0.5504 - loss: 0.8799 - val_accuracy: 0.5651 - val_loss: 0.9213\nEpoch 5/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 512ms/step - accuracy: 0.5945 - loss: 0.8372 - val_accuracy: 0.6012 - val_loss: 0.8763\nEpoch 6/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 506ms/step - accuracy: 0.6436 - loss: 0.7613 - val_accuracy: 0.6415 - val_loss: 0.8566\nEpoch 7/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 507ms/step - accuracy: 0.6876 - loss: 0.6964 - val_accuracy: 0.6444 - val_loss: 0.8063\nEpoch 8/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 506ms/step - accuracy: 0.7228 - loss: 0.6372 - val_accuracy: 0.6903 - val_loss: 0.7406\nEpoch 9/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 506ms/step - accuracy: 0.7660 - loss: 0.5556 - val_accuracy: 0.7379 - val_loss: 0.6589\nEpoch 10/10\n\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 510ms/step - accuracy: 0.8218 - loss: 0.4602 - val_accuracy: 0.7580 - val_loss: 0.5988\n\u001b[1m58/58\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 330ms/step - accuracy: 0.7830 - loss: 0.5755\nTest Accuracy for Sagittal_T1: 0.7725\n\nTraining model for series description: Sagittal_T2_STIR\nFound 2343 validated image filenames belonging to 3 classes.\nFound 1256 validated image filenames belonging to 3 classes.\nFound 1210 validated image filenames belonging to 3 classes.\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 991 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 540 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:920: UserWarning: Found 500 invalid image filename(s) in x_col=\"image_path\". These filename(s) will be ignored.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/10\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n  self._warn_if_super_not_called()\n","output_type":"stream"},{"name":"stdout","text":"\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.4049 - loss: 1.4835 - val_accuracy: 0.5080 - val_loss: 1.0036\nEpoch 2/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 498ms/step - accuracy: 0.5171 - loss: 0.9260 - val_accuracy: 0.5406 - val_loss: 0.9788\nEpoch 3/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 497ms/step - accuracy: 0.5687 - loss: 0.8956 - val_accuracy: 0.6290 - val_loss: 0.9355\nEpoch 4/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 501ms/step - accuracy: 0.6238 - loss: 0.8320 - val_accuracy: 0.6059 - val_loss: 0.9887\nEpoch 5/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 499ms/step - accuracy: 0.6694 - loss: 0.7677 - val_accuracy: 0.5518 - val_loss: 0.9359\nEpoch 6/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 497ms/step - accuracy: 0.6864 - loss: 0.7558 - val_accuracy: 0.7150 - val_loss: 0.8212\nEpoch 7/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 499ms/step - accuracy: 0.7261 - loss: 0.6646 - val_accuracy: 0.7253 - val_loss: 0.8248\nEpoch 8/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 491ms/step - accuracy: 0.7837 - loss: 0.5807 - val_accuracy: 0.6553 - val_loss: 0.8252\nEpoch 9/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 501ms/step - accuracy: 0.7736 - loss: 0.5637 - val_accuracy: 0.7468 - val_loss: 0.7099\nEpoch 10/10\n\u001b[1m37/37\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 503ms/step - accuracy: 0.8142 - loss: 0.5137 - val_accuracy: 0.7898 - val_loss: 0.6464\n\u001b[1m19/19\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 617ms/step - accuracy: 0.7843 - loss: 0.6555\nTest Accuracy for Sagittal_T2_STIR: 0.7884\n","output_type":"stream"}]},{"cell_type":"code","source":"# Assuming 'expanded_test_desc' already exists and contains the image paths and row IDs\n# Create a directory for the models\nmodels_directory = '/kaggle/working'  # Update with your actual models directory\n\n# Initialize an empty list to collect predictions\nsubmission_data = []\n\n# Get unique series descriptions from the existing DataFrame\nseries_descriptions = expanded_test_desc['series_description'].unique()\n\n\n# Loop through each unique series description\nfor series in series_descriptions:\n    print(f\"\\nProcessing series: {series}\")\n    \n    # Load the corresponding model\n    model_path = os.path.join(models_directory, f\"{series}_model.h5\")\n    \n    try:\n        model = load_model(model_path)\n    except Exception as e:\n        print(f\"Error loading model for {series}: {e}\")\n        continue\n    \n    # Filter the DataFrame for the current series\n    series_df = expanded_test_desc[expanded_test_desc['series_description'] == series]\n    \n    # Create a test data generator\n    test_datagen = ImageDataGenerator(rescale=1./255)  # Rescale pixel values\n    test_generator = test_datagen.flow_from_dataframe(\n        dataframe=expanded_test_desc,\n        x_col='image_path',\n        y_col=None,  # No labels for test data\n        class_mode=None,\n        target_size=(320, 320),  # Adjust to your model's expected input size\n        batch_size=32,\n        shuffle=False,\n        seed=42\n    )\n    \n    # Make predictions\n    predictions = model.predict(test_generator, verbose=1)\n\n    # Convert predictions to probabilities\n    for idx, row in enumerate(series_df.itertuples()):\n        row_id = row.row_id\n        pred = predictions[idx]\n\n        # Assuming the model outputs class scores for normal/mild, moderate, and severe\n        normal_mild_prob = pred[0]  # Replace with appropriate index if necessary\n        moderate_prob = pred[1]      # Replace with appropriate index if necessary\n        severe_prob = pred[2]        # Replace with appropriate index if necessary\n\n        # Append the results to the submission data\n        submission_data.append({\n            'row_id': row_id,\n            'normal_mild': normal_mild_prob,\n            'moderate': moderate_prob,\n            'severe': severe_prob\n        })\n\n# Create a DataFrame for submission\nsubmission_df = pd.DataFrame(submission_data)\n\n\n# Set the display format for floating-point numbers to show decimals\npd.options.display.float_format = '{:.8f}'.format  # Change the number of decimal places as needed\n\n\n# Save the submission DataFrame to a CSV file\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission DataFrame created successfully.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-23T12:36:16.850698Z","iopub.execute_input":"2024-09-23T12:36:16.851759Z","iopub.status.idle":"2024-09-23T12:36:21.757314Z","shell.execute_reply.started":"2024-09-23T12:36:16.851713Z","shell.execute_reply":"2024-09-23T12:36:21.756387Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stdout","text":"\nProcessing series: Sagittal_T1\nFound 194 validated image filenames.\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 127ms/step\n\nProcessing series: Axial_T2\nFound 194 validated image filenames.\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 119ms/step\n\nProcessing series: Sagittal_T2_STIR\nFound 194 validated image filenames.\n\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 115ms/step\nSubmission DataFrame created successfully.\n","output_type":"stream"}]},{"cell_type":"code","source":"expanded_test_desc[\"row_id\"].value_counts()","metadata":{"execution":{"iopub.status.busy":"2024-09-23T12:36:32.693610Z","iopub.execute_input":"2024-09-23T12:36:32.694025Z","iopub.status.idle":"2024-09-23T12:36:32.703647Z","shell.execute_reply.started":"2024-09-23T12:36:32.693986Z","shell.execute_reply":"2024-09-23T12:36:32.702238Z"},"trusted":true},"execution_count":56,"outputs":[{"execution_count":56,"output_type":"execute_result","data":{"text/plain":"row_id\n44036939_spinal_canal_stenosis_l4_l5               10\n44036939_spinal_canal_stenosis_l5_s1               10\n44036939_spinal_canal_stenosis_l3_l4               10\n44036939_spinal_canal_stenosis_l2_l3               10\n44036939_spinal_canal_stenosis_l1_l2               10\n44036939_right_subarticular_stenosis_l4_l5         10\n44036939_right_subarticular_stenosis_l3_l4         10\n44036939_left_subarticular_stenosis_l2_l3          10\n44036939_left_subarticular_stenosis_l1_l2          10\n44036939_right_subarticular_stenosis_l5_s1          9\n44036939_left_subarticular_stenosis_l4_l5           9\n44036939_left_subarticular_stenosis_l3_l4           9\n44036939_left_subarticular_stenosis_l5_s1           9\n44036939_right_subarticular_stenosis_l1_l2          9\n44036939_right_subarticular_stenosis_l2_l3          9\n44036939_right_neural_foraminal_narrowing_l4_l5     5\n44036939_left_neural_foraminal_narrowing_l2_l3      5\n44036939_left_neural_foraminal_narrowing_l1_l2      5\n44036939_right_neural_foraminal_narrowing_l3_l4     5\n44036939_right_neural_foraminal_narrowing_l2_l3     5\n44036939_right_neural_foraminal_narrowing_l1_l2     5\n44036939_left_neural_foraminal_narrowing_l5_s1      5\n44036939_left_neural_foraminal_narrowing_l4_l5      5\n44036939_left_neural_foraminal_narrowing_l3_l4      5\n44036939_right_neural_foraminal_narrowing_l5_s1     5\nName: count, dtype: int64"},"metadata":{}}]},{"cell_type":"code","source":"# Count occurrences of each unique row_id\nrow_id_counts = submission_df['row_id'].value_counts()\n\n# Group by 'row_id' and calculate the mean for each group\nmean_df = submission_df.groupby('row_id').mean().reset_index()\n\n# Display the mean DataFrame\nmean_df","metadata":{"execution":{"iopub.status.busy":"2024-09-23T12:36:36.018916Z","iopub.execute_input":"2024-09-23T12:36:36.019328Z","iopub.status.idle":"2024-09-23T12:36:36.038379Z","shell.execute_reply.started":"2024-09-23T12:36:36.019281Z","shell.execute_reply":"2024-09-23T12:36:36.037227Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"                                             row_id  normal_mild   moderate  \\\n0    44036939_left_neural_foraminal_narrowing_l1_l2   0.65952271 0.12109806   \n1    44036939_left_neural_foraminal_narrowing_l2_l3   0.47745237 0.05419617   \n2    44036939_left_neural_foraminal_narrowing_l3_l4   0.57662284 0.18902835   \n3    44036939_left_neural_foraminal_narrowing_l4_l5   0.52638257 0.12610979   \n4    44036939_left_neural_foraminal_narrowing_l5_s1   0.44783497 0.13753089   \n5         44036939_left_subarticular_stenosis_l1_l2   0.88829786 0.00184982   \n6         44036939_left_subarticular_stenosis_l2_l3   0.89754641 0.00471216   \n7         44036939_left_subarticular_stenosis_l3_l4   0.85379273 0.00334296   \n8         44036939_left_subarticular_stenosis_l4_l5   0.96247536 0.00059654   \n9         44036939_left_subarticular_stenosis_l5_s1   0.90697563 0.00394123   \n10  44036939_right_neural_foraminal_narrowing_l1_l2   0.65952271 0.12109806   \n11  44036939_right_neural_foraminal_narrowing_l2_l3   0.47745237 0.05419617   \n12  44036939_right_neural_foraminal_narrowing_l3_l4   0.57662284 0.18902835   \n13  44036939_right_neural_foraminal_narrowing_l4_l5   0.52638257 0.12610979   \n14  44036939_right_neural_foraminal_narrowing_l5_s1   0.44783497 0.13753089   \n15       44036939_right_subarticular_stenosis_l1_l2   0.35320571 0.21947213   \n16       44036939_right_subarticular_stenosis_l2_l3   0.26019895 0.33616334   \n17       44036939_right_subarticular_stenosis_l3_l4   0.44467825 0.27753708   \n18       44036939_right_subarticular_stenosis_l4_l5   0.39516535 0.23017077   \n19       44036939_right_subarticular_stenosis_l5_s1   0.41878971 0.25703776   \n20             44036939_spinal_canal_stenosis_l1_l2   0.44103351 0.12192453   \n21             44036939_spinal_canal_stenosis_l2_l3   0.48364791 0.13273098   \n22             44036939_spinal_canal_stenosis_l3_l4   0.43431550 0.12364912   \n23             44036939_spinal_canal_stenosis_l4_l5   0.46044508 0.12565878   \n24             44036939_spinal_canal_stenosis_l5_s1   0.46918672 0.12791221   \n\n       severe  \n0  0.21937919  \n1  0.46835145  \n2  0.23434874  \n3  0.34750766  \n4  0.41463414  \n5  0.10985237  \n6  0.09774145  \n7  0.14286438  \n8  0.03692815  \n9  0.08908312  \n10 0.21937919  \n11 0.46835145  \n12 0.23434874  \n13 0.34750766  \n14 0.41463414  \n15 0.42732215  \n16 0.40363771  \n17 0.27778468  \n18 0.37466389  \n19 0.32417256  \n20 0.43704200  \n21 0.38362113  \n22 0.44203538  \n23 0.41389614  \n24 0.40290108  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>row_id</th>\n      <th>normal_mild</th>\n      <th>moderate</th>\n      <th>severe</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>44036939_left_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.65952271</td>\n      <td>0.12109806</td>\n      <td>0.21937919</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>44036939_left_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.47745237</td>\n      <td>0.05419617</td>\n      <td>0.46835145</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>44036939_left_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.57662284</td>\n      <td>0.18902835</td>\n      <td>0.23434874</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>44036939_left_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.52638257</td>\n      <td>0.12610979</td>\n      <td>0.34750766</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>44036939_left_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.44783497</td>\n      <td>0.13753089</td>\n      <td>0.41463414</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>44036939_left_subarticular_stenosis_l1_l2</td>\n      <td>0.88829786</td>\n      <td>0.00184982</td>\n      <td>0.10985237</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>44036939_left_subarticular_stenosis_l2_l3</td>\n      <td>0.89754641</td>\n      <td>0.00471216</td>\n      <td>0.09774145</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>44036939_left_subarticular_stenosis_l3_l4</td>\n      <td>0.85379273</td>\n      <td>0.00334296</td>\n      <td>0.14286438</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>44036939_left_subarticular_stenosis_l4_l5</td>\n      <td>0.96247536</td>\n      <td>0.00059654</td>\n      <td>0.03692815</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>44036939_left_subarticular_stenosis_l5_s1</td>\n      <td>0.90697563</td>\n      <td>0.00394123</td>\n      <td>0.08908312</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>44036939_right_neural_foraminal_narrowing_l1_l2</td>\n      <td>0.65952271</td>\n      <td>0.12109806</td>\n      <td>0.21937919</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>44036939_right_neural_foraminal_narrowing_l2_l3</td>\n      <td>0.47745237</td>\n      <td>0.05419617</td>\n      <td>0.46835145</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>44036939_right_neural_foraminal_narrowing_l3_l4</td>\n      <td>0.57662284</td>\n      <td>0.18902835</td>\n      <td>0.23434874</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>44036939_right_neural_foraminal_narrowing_l4_l5</td>\n      <td>0.52638257</td>\n      <td>0.12610979</td>\n      <td>0.34750766</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>44036939_right_neural_foraminal_narrowing_l5_s1</td>\n      <td>0.44783497</td>\n      <td>0.13753089</td>\n      <td>0.41463414</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>44036939_right_subarticular_stenosis_l1_l2</td>\n      <td>0.35320571</td>\n      <td>0.21947213</td>\n      <td>0.42732215</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>44036939_right_subarticular_stenosis_l2_l3</td>\n      <td>0.26019895</td>\n      <td>0.33616334</td>\n      <td>0.40363771</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>44036939_right_subarticular_stenosis_l3_l4</td>\n      <td>0.44467825</td>\n      <td>0.27753708</td>\n      <td>0.27778468</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>44036939_right_subarticular_stenosis_l4_l5</td>\n      <td>0.39516535</td>\n      <td>0.23017077</td>\n      <td>0.37466389</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>44036939_right_subarticular_stenosis_l5_s1</td>\n      <td>0.41878971</td>\n      <td>0.25703776</td>\n      <td>0.32417256</td>\n    </tr>\n    <tr>\n      <th>20</th>\n      <td>44036939_spinal_canal_stenosis_l1_l2</td>\n      <td>0.44103351</td>\n      <td>0.12192453</td>\n      <td>0.43704200</td>\n    </tr>\n    <tr>\n      <th>21</th>\n      <td>44036939_spinal_canal_stenosis_l2_l3</td>\n      <td>0.48364791</td>\n      <td>0.13273098</td>\n      <td>0.38362113</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>44036939_spinal_canal_stenosis_l3_l4</td>\n      <td>0.43431550</td>\n      <td>0.12364912</td>\n      <td>0.44203538</td>\n    </tr>\n    <tr>\n      <th>23</th>\n      <td>44036939_spinal_canal_stenosis_l4_l5</td>\n      <td>0.46044508</td>\n      <td>0.12565878</td>\n      <td>0.41389614</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>44036939_spinal_canal_stenosis_l5_s1</td>\n      <td>0.46918672</td>\n      <td>0.12791221</td>\n      <td>0.40290108</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]}]}