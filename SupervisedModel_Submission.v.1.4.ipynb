{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":71549,"databundleVersionId":8561470,"sourceType":"competition"}],"dockerImageVersionId":30761,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Basic Libraries\nimport os\nimport shutil\nimport random\nimport numpy as np\nimport pandas as pd\n\n# Image Processing\nimport cv2\nfrom PIL import Image, ImageEnhance\nfrom skimage.util import random_noise\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\n\n# TensorFlow and Keras for Deep Learning\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Attention, Add, Dense, GlobalAveragePooling2D, Input\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.optimizers import Adam, RMSprop\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\n# Scikit-learn for Model Preparation\nfrom sklearn.utils import resample\nfrom sklearn.model_selection import train_test_split\n\n# Additional Libraries for Image Handling and File Operations\nimport glob\nimport matplotlib.image as mpimg\nimport pydicom\n\n#Augmentation\nfrom concurrent.futures import ThreadPoolExecutor\nfrom albumentations import (\n    HorizontalFlip, VerticalFlip, Rotate, RandomBrightnessContrast,\n    ColorJitter, GridDistortion, RandomGamma, GaussNoise, Compose,\n    CLAHE, Solarize, Posterize, ShiftScaleRotate, ElasticTransform,\n    ToGray, HueSaturationValue\n)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-09T17:04:34.651114Z","iopub.execute_input":"2024-09-09T17:04:34.651495Z","iopub.status.idle":"2024-09-09T17:04:47.969123Z","shell.execute_reply.started":"2024-09-09T17:04:34.651454Z","shell.execute_reply":"2024-09-09T17:04:47.968232Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load datasets\ndf_train = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train.csv\")\ndf_train_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_series_descriptions.csv\")\ndf_label_coord = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_label_coordinates.csv\")\n#df_train_imagess = pd.read_csv(\"/kaggle/working/df_png_paths.csv\")\n\n# Load datasets\ndf_test_series_descriptions = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n#df_train_imagess = pd.read_csv(\"/kaggle/working/df_png_paths.csv\")\n\n# Output Paths\noutput_path = '/kaggle/working/train_images'\n# Define the directory where your augmented images are saved\noutput_images_dir = '/kaggle/working/augmented_images'\n\n# Path to the input and output directories\ninput_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/'","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:04:47.970895Z","iopub.execute_input":"2024-09-09T17:04:47.971427Z","iopub.status.idle":"2024-09-09T17:04:48.125201Z","shell.execute_reply.started":"2024-09-09T17:04:47.971393Z","shell.execute_reply":"2024-09-09T17:04:48.124403Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create image paths\ndf_label_coord['image_path'] = \"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/train_images/\" + \\\n                               df_label_coord['study_id'].astype(str) + \"/\" + \\\n                               df_label_coord['series_id'].astype(str) + \"/\" + \\\n                               df_label_coord['instance_number'].astype(str) + \".dcm\"\n\n# Melt the df_train DataFrame\ndf_train_melted = df_train.melt(id_vars=['study_id'], var_name='condition_level', value_name='severity')\n\n# Split 'condition_level' to extract 'condition' and 'level'\ndf_train_melted[['conditions', 'level']] = df_train_melted['condition_level'].str.rsplit('_', n=2, expand=True).iloc[:, 1:]\ndf_train_melted['condition'] = df_train_melted['condition_level'].apply(lambda x: '_'.join(x.split('_')[:-2])).str.replace(\"_\", \" \").str.title()\ndf_train_melted['level'] = df_train_melted['conditions'].str.upper() + \"/\" + df_train_melted['level'].str.upper()\n\n# Drop the original 'condition_level' column\ndf_train_melted = df_train_melted.drop(columns=['condition_level', 'conditions'])\n\n# Merge DataFrames on 'study_id', 'level', and 'condition'\ndf_final = pd.merge(df_label_coord, df_train_melted, on=['study_id', 'level', 'condition'], how='inner')\n\n# Ensure the 'series_description' column exists before trying to reorder\nif 'series_description' in df_train_series_descriptions.columns:\n    # Merge df_final with df_train_series_descriptions on 'study_id' and 'series_id'\n    df_final_filtered = pd.merge(df_final, df_train_series_descriptions[['study_id', 'series_id', 'series_description']],\n                                 on=['study_id', 'series_id'], how='left')\n\n    # Reorder columns to place 'series_description' immediately after 'series_id'\n    columns_order = ['study_id', 'series_id', 'series_description', 'instance_number', 'condition', 'level', 'x', 'y', 'image_path', 'severity']\n    \n    # Ensure that 'series_description' exists in the DataFrame before reordering columns\n    if 'series_description' in df_final_filtered.columns:\n        df_final_filtered = df_final_filtered[columns_order]\n    else:\n        print(\"Warning: 'series_description' column not found after merging.\")\nelse:\n    print(\"Warning: 'series_description' column not found in the input data.\")\n    \ndf_final_filtered.sample()","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:04:48.126306Z","iopub.execute_input":"2024-09-09T17:04:48.126613Z","iopub.status.idle":"2024-09-09T17:04:48.602109Z","shell.execute_reply.started":"2024-09-09T17:04:48.126581Z","shell.execute_reply":"2024-09-09T17:04:48.601241Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Function to convert DICOM pixel array to PNG\ndef readdcm_writepng_image(src_dicom_pixelarray, dest_path_png):\n    src_dicom_pixelarray = np.array(src_dicom_pixelarray)\n    standardized_image_data = ((src_dicom_pixelarray - src_dicom_pixelarray.min()) / \n                               (src_dicom_pixelarray.max() - src_dicom_pixelarray.min() + 1e-10)) * 255\n    standardized_image_data = standardized_image_data.astype(np.uint8)\n    final_image_to_png = cv2.resize(standardized_image_data, (320, 320), interpolation=cv2.INTER_CUBIC)\n    cv2.imwrite(dest_path_png, final_image_to_png)\n\n# Remove previous output directory for fresh writing\nif os.path.isdir(output_path):\n    shutil.rmtree(output_path)\n\n# Drop duplicates based on 'image_path' to ensure each image is converted only once\nunique_images_df = df_final_filtered.drop_duplicates(subset='image_path')\n\n# Create a new DataFrame to store paths to the converted images\ndf_png_paths = pd.DataFrame(columns=df_final_filtered.columns)\n\n# Convert only unique labeled images\nfor index, row in tqdm(unique_images_df.iterrows(), total=len(unique_images_df)):\n    study_id = row['study_id']\n    # Apply the replacement to series_description\n    series_description = row['series_description'].replace(' ', '_').replace('/', '_')\n    instance_number = row['instance_number']\n    \n    # Construct the destination path for the PNG file\n    dest_path = f'{output_path}/{study_id}/{series_description}/{instance_number}.png'\n    \n    # Ensure directory exists\n    os.makedirs(os.path.dirname(dest_path), exist_ok=True)\n    \n    # Read the DICOM image and convert it to PNG\n    dicom_image = pydicom.dcmread(row['image_path'])\n    readdcm_writepng_image(dicom_image.pixel_array, dest_path)\n    \n    # Copy the row and update the image path to the new PNG path\n    new_row = row.copy()\n    new_row['image_path'] = dest_path\n    \n    # Replace series_description in the new_row DataFrame\n    new_row['series_description'] = series_description\n    \n    # Append the new row to the new DataFrame using pd.concat\n    df_png_paths = pd.concat([df_png_paths, pd.DataFrame([new_row])], ignore_index=True)\n\nprint(\"Conversion to PNG completed.\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:04:48.604766Z","iopub.execute_input":"2024-09-09T17:04:48.605086Z","iopub.status.idle":"2024-09-09T17:15:51.593477Z","shell.execute_reply.started":"2024-09-09T17:04:48.605052Z","shell.execute_reply":"2024-09-09T17:15:51.592455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Ensure output directory exists\nos.makedirs(output_images_dir, exist_ok=True)\n\n# Step 2: Assume df_png_paths is already defined with the necessary data\n# You need to format the series_description\ndf_augmented = df_png_paths.copy()\ndf_augmented['series_description'] = df_augmented['series_description'].str.replace(r'[ /]', '_', regex=True)\n\n# Step 3: Define color map augmentation functions\ndef apply_color_map(image, colormap):\n    return cv2.applyColorMap(image, colormap)\n\n# Step 4: Define augmentation techniques\nalbumentations_augmentations = [\n    Compose([Rotate(limit=90), HorizontalFlip()]),\n    Compose([Rotate(limit=180)]),\n    Compose([Rotate(limit=270), HorizontalFlip()]),\n    Compose([ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2)]),\n    Compose([GaussNoise(), VerticalFlip()]),\n    Compose([GridDistortion()]),\n    Compose([ShiftScaleRotate(shift_limit=0.05, scale_limit=0.1, rotate_limit=15)]),\n    Compose([ElasticTransform(alpha=1, sigma=50, alpha_affine=None)]),  # Updated line\n    Compose([CLAHE(), HueSaturationValue(hue_shift_limit=20, sat_shift_limit=30, val_shift_limit=20)]),\n    Compose([Solarize(threshold=128.0), Posterize(num_bits=4)]),\n    Compose([ToGray()])\n]\n\ncolor_map_augmentations = [\n    (cv2.COLORMAP_VIRIDIS, 'viridis'),\n    (cv2.COLORMAP_PLASMA, 'plasma'),\n    (cv2.COLORMAP_INFERNO, 'inferno'),\n    (cv2.COLORMAP_MAGMA, 'magma'),\n]\n\n# Combine all augmentations into one list\nall_augmentations = albumentations_augmentations + color_map_augmentations\n\n# Define how many times to augment each image for Moderate and Severe classes\nnum_augmentations_per_image_severe = 10 # Augment each 'Severe' image 6 times\nnum_augmentations_per_image_moderate = 4  # Augment each 'Moderate' image 1 time\n\ndef augment_image(row):\n    image_path = row['image_path']\n    image = cv2.imread(image_path)  # Load the image using OpenCV\n\n    # Check if the image was loaded successfully\n    if image is None:\n        print(f\"Warning: Unable to load image at path: {image_path}\")\n        return []  # Return an empty list if the image could not be loaded\n\n    coords = [row['x'], row['y']]  # Extract coordinates\n    augmented_images = []  # Store augmented images for this row\n    image_height, image_width = image.shape[:2]\n\n    # Determine the number of augmentations based on severity\n    if row['severity'] == 'Severe':\n        num_augmentations = num_augmentations_per_image_severe\n    elif row['severity'] == 'Moderate':\n        num_augmentations = num_augmentations_per_image_moderate\n    else:\n        return []  # Skip if severity is not 'Moderate' or 'Severe'\n\n    for _ in range(num_augmentations):\n        # Choose an augmentation\n        aug_index = np.random.choice(len(all_augmentations))\n        aug = all_augmentations[aug_index]\n\n        try:\n            if isinstance(aug, tuple):\n                # Apply the color map augmentation\n                colormap, name = aug\n                image_aug = apply_color_map(image, colormap)\n                aug_name = name  # Use the color map name directly\n            else:\n                # Apply the Albumentations augmentation\n                augmented = aug(image=image)\n                image_aug = augmented['image']\n\n                # Get the augmentation names\n                aug_name = '_'.join([type(t).__name__ for t in aug.transforms])\n\n                # Update coordinates based on the applied transformations\n                for t in aug.transforms:\n                    if isinstance(t, HorizontalFlip):\n                        coords[0] = image_width - coords[0]\n                    if isinstance(t, VerticalFlip):\n                        coords[1] = image_height - coords[1]\n                    if isinstance(t, Rotate):\n                        angle = t.limit if isinstance(t.limit, (int, float)) else t.limit[1]\n                        if angle == 90:\n                            coords = [coords[1], image_width - coords[0]]\n                        elif angle == 180:\n                            coords = [image_width - coords[0], image_height - coords[1]]\n                        elif angle == 270:\n                            coords = [image_height - coords[1], coords[0]]\n\n            # Create subfolder structure\n            study_id = row['study_id']\n            series_description = row['series_description'].replace(' ', '_')  # Replace spaces with underscores\n            output_subfolder = os.path.join(output_images_dir, str(study_id), series_description)\n            os.makedirs(output_subfolder, exist_ok=True)\n\n            # Generate new file name with the augmentation name and instance number\n            instance_number = row['instance_number']\n            augmented_image_path = os.path.join(output_subfolder, f\"{aug_name}_{instance_number}.png\")\n\n            # Save the augmented image\n            cv2.imwrite(augmented_image_path, image_aug)\n\n            augmented_images.append({\n                'study_id': study_id,\n                'series_description': series_description,\n                'instance_number': instance_number,\n                'x': coords[0],\n                'y': coords[1],\n                'condition': row['condition'],\n                'level': row['level'],\n                'image_path': augmented_image_path,\n                'severity': row['severity']\n            })\n        except Exception as e:\n            print(f\"Error processing image {image_path}: {e}\")\n\n    return augmented_images\n\n\n# Step 7: Filter only Moderate and Severe classes for augmentation\ndf_filtered = df_augmented[df_augmented['severity'].isin(['Moderate', 'Severe'])]\n\n# Step 8: Use parallel processing to augment images\naugmented_data = []\n\nwith ThreadPoolExecutor() as executor:\n    results = list(tqdm(executor.map(augment_image, [row for _, row in df_filtered.iterrows()]), total=len(df_filtered)))\n\n# Flatten the results and filter out None values\naugmented_data = [item for sublist in results for item in sublist if item is not None]\n\n# Step 9: Collect the results into a DataFrame\ndf_augmented_final = pd.DataFrame(augmented_data)\n\nprint(f\"Total processed images: {len(augmented_data)}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:15:51.594890Z","iopub.execute_input":"2024-09-09T17:15:51.595549Z","iopub.status.idle":"2024-09-09T17:18:06.080757Z","shell.execute_reply.started":"2024-09-09T17:15:51.595477Z","shell.execute_reply":"2024-09-09T17:18:06.079770Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Drop rows with severity equal to 0 or NaN\ndf_final_filtered_cleaned = df_converted_data[(df_converted_data['severity'] != 0) & (df_converted_data['severity'].notna())]\ndf_augmented_cleaned = df_augmented_final[(df_augmented_final['severity'] != 0) & (df_augmented_final['severity'].notna())]\n\n# Display the resulting DataFrame\nprint(f\"Data after removing rows with severity 0 or NaN: {df_final_filtered_cleaned.shape[0]} samples\")\nprint(f\"Data after removing rows with severity 0 or NaN: {df_augmented_cleaned.shape[0]} samples\")\n\n# Concatenate the cleaned DataFrames\ndf_concat = pd.concat([df_final_filtered_cleaned, df_augmented_cleaned], ignore_index=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:18:06.095589Z","iopub.execute_input":"2024-09-09T17:18:06.095884Z","iopub.status.idle":"2024-09-09T17:18:06.795145Z","shell.execute_reply.started":"2024-09-09T17:18:06.095852Z","shell.execute_reply":"2024-09-09T17:18:06.794163Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count current instances in each class\nprint(df_concat[\"severity\"].value_counts())\n\n# Define the target number for balancing (the maximum count from 'Normal/Mild')\ntarget_count = df_concat[\"severity\"].value_counts().max()\n\n# Oversampling the 'Severe' and 'Moderate' classes\ndf_severe = df_concat[df_concat[\"severity\"] == \"Severe\"]\ndf_moderate = df_concat[df_concat[\"severity\"] == \"Moderate\"]\ndf_normal_mild = df_concat[df_concat[\"severity\"] == \"Normal/Mild\"]\n\n# Create balanced DataFrames by oversampling\ndf_severe_oversampled = df_severe.sample(target_count, replace=True, random_state=42)\ndf_moderate_oversampled = df_moderate.sample(target_count, replace=True, random_state=42)\n\n# Combine all classes into a single DataFrame\ndf_balanced = pd.concat([df_normal_mild, df_severe_oversampled, df_moderate_oversampled], ignore_index=True)\n\n# Shuffle the balanced DataFrame\ndf_resampled = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n\n# Check the class distribution after balancing\nprint(df_resampled[\"severity\"].value_counts())","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-09-09T17:18:06.796280Z","iopub.execute_input":"2024-09-09T17:18:06.796652Z","iopub.status.idle":"2024-09-09T17:18:06.916172Z","shell.execute_reply.started":"2024-09-09T17:18:06.796615Z","shell.execute_reply":"2024-09-09T17:18:06.915267Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_and_remove_corrupted_images(directory):\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.lower().endswith(('.png')):\n                try:\n                    img = Image.open(os.path.join(root, file))\n                    img.verify()  # This will raise an exception if the file is corrupted\n                except Exception as e:\n                    corrupted_image_path = os.path.join(root, file)\n                    print(f\"Removing corrupted image: {corrupted_image_path} - Error: {e}\")\n                    os.remove(corrupted_image_path)  # Remove the corrupted image\n\ncheck_and_remove_corrupted_images('/kaggle/train_images/')\ncheck_and_remove_corrupted_images('/kaggle/augmented_images/')","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:18:06.917460Z","iopub.execute_input":"2024-09-09T17:18:06.917875Z","iopub.status.idle":"2024-09-09T17:18:06.925360Z","shell.execute_reply.started":"2024-09-09T17:18:06.917832Z","shell.execute_reply":"2024-09-09T17:18:06.924414Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split the data into training, validation, and test sets\ntrain_df, test_df = train_test_split(df_resampled, test_size=0.3, stratify=df_resampled['severity'])\ntrain_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['severity'])\n\n# Create ImageDataGenerator with rescaling\ndatagen = ImageDataGenerator(rescale=1./255)\n\n# Create data generators for train, validation, and test sets\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=train_df,\n    x_col='image_path',\n    y_col='severity',\n    target_size=(320, 320),  # Resize images to 256x256\n    batch_size=8,            # Batch size for training\n    class_mode='categorical', # Use 'categorical' for multi-class classification\n    shuffle=True              # Shuffle the training data\n)\n\nval_generator = datagen.flow_from_dataframe(\n    dataframe=val_df,\n    x_col='image_path',\n    y_col='severity',\n    target_size=(320, 320),  # Resize images to 256x256\n    batch_size=8,            # Batch size for validation\n    class_mode='categorical', # Use 'categorical' for multi-class classification\n    shuffle=False              # Do not shuffle validation data\n)\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=test_df,\n    x_col='image_path',\n    y_col='severity',\n    target_size=(320, 320),  # Resize images to 256x256\n    batch_size=8,            # Batch size for testing\n    class_mode='categorical', # Use 'categorical' for multi-class classification\n    shuffle=False              # Do not shuffle test data\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T17:18:06.929219Z","iopub.execute_input":"2024-09-09T17:18:06.929682Z","iopub.status.idle":"2024-09-09T17:18:07.772665Z","shell.execute_reply.started":"2024-09-09T17:18:06.929650Z","shell.execute_reply":"2024-09-09T17:18:07.771875Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the class names\nclass_names = ['Moderate', 'Normal/Mild', 'Severe']\n\n# Build the CNN model with Batch Normalization\nmodel = Sequential([\n    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(320, 320, 3)),\n    BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(64, (3, 3), activation='relu'),\n    BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Conv2D(128, (3, 3), activation='relu'),\n    BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dropout(0.2),\n    layers.Dense(len(class_names), activation='softmax')\n])\n\n# Compile the model\nmodel.compile(\n    optimizer=tf.keras.optimizers.Nadam(learning_rate=0.0001),  # Experiment with the learning rate\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\n# Adjust callbacks as needed\ncallbacks = [\n    EarlyStopping(patience=10, restore_best_weights=True, verbose=1),\n    ModelCheckpoint('/kaggle/working/best_model.keras', save_best_only=True, verbose=1),\n    ReduceLROnPlateau(factor=0.5, patience=3, min_lr=1e-6, verbose=1)\n]\n\n# Fit the model with the updated architecture and parameters\nhistory = model.fit(\n    train_generator,\n    validation_data=val_generator,\n    epochs=25,\n    verbose=1,\n    callbacks=callbacks\n)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T18:17:34.150971Z","iopub.execute_input":"2024-09-09T18:17:34.151624Z","iopub.status.idle":"2024-09-09T19:08:02.834129Z","shell.execute_reply.started":"2024-09-09T18:17:34.151585Z","shell.execute_reply":"2024-09-09T19:08:02.833270Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_loss, test_accuracy = model.evaluate(test_generator)\nprint(f\"Test Loss: {test_loss}\")\nprint(f\"Test Accuracy: {test_accuracy}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-09T19:12:19.538439Z","iopub.execute_input":"2024-09-09T19:12:19.539426Z","iopub.status.idle":"2024-09-09T19:13:20.320773Z","shell.execute_reply.started":"2024-09-09T19:12:19.539385Z","shell.execute_reply":"2024-09-09T19:13:20.319841Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from glob import glob\n\n# Load the test series descriptions\ndf_test_series = pd.read_csv(\"/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv\")\n\n# Define paths\ntest_images_path = '/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_images'\n\n\ndef readdcm_writepng_image(src_dicom_pixelarray, dest_path_png):\n    '''\n    Convert DICOM pixel array to PNG with standardized pixel intensity.\n    '''\n    standardized_image_data = ((src_dicom_pixelarray - src_dicom_pixelarray.min()) / \n                               (src_dicom_pixelarray.max() - src_dicom_pixelarray.min() + 1e-10)) * 255\n    final_image_to_png = cv2.resize(standardized_image_data, (320, 320), interpolation=cv2.INTER_CUBIC)\n    cv2.imwrite(dest_path_png, final_image_to_png)\n\n# Remove the output directory if it exists (for fresh conversion)\nif os.path.isdir(output_path):\n    shutil.rmtree(output_path)\n\n# Iterate over the test data\nfor idx, row in tqdm(df_test_series.iterrows(), total=len(df_test_series)):\n    study_id = row['study_id']\n    series_id = row['series_id']\n    series_desc = row['series_description'].replace(' ', '_').replace('/', '_')\n    \n    # Define the new directory structure for PNGs\n    series_output_dir = f'{output_path}/{study_id}/{series_desc}'\n    os.makedirs(series_output_dir, exist_ok=True)\n    \n    # Get all DICOM files in this series\n    series_dicom_dir = f'{test_images_path}/{study_id}/{series_id}'\n    dicom_files = glob(f'{series_dicom_dir}/*.dcm')\n    \n    # Convert each DICOM file to PNG\n    for dicom_file in dicom_files:\n        dicom_image = pydicom.dcmread(dicom_file)\n        image_filename = os.path.splitext(os.path.basename(dicom_file))[0]  # Use SOPInstanceUID for naming\n        image_dicom_pixelarray = dicom_image.pixel_array\n        \n        dest_path = f'{series_output_dir}/{image_filename}.png'\n        readdcm_writepng_image(image_dicom_pixelarray, dest_path)\n# Example of how to display images\nfor study_id in df_test_series['study_id'].unique():\n    study_dir = f'{output_path}/{study_id}'\n    \n    for series_desc in os.listdir(study_dir):\n        print(f'Series description: {series_desc}')\n        png_files = glob(f'{study_dir}/{series_desc}/*.png')\n        \n        for png_file in png_files[:5]:  # Display first 5 images\n            img = Image.open(png_file)\n            plt.imshow(img, cmap='gray')\n            plt.title(f'{series_desc} - {os.path.basename(png_file)}')\n            plt.axis('off')\n            plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-09T19:13:39.990087Z","iopub.execute_input":"2024-09-09T19:13:39.990473Z","iopub.status.idle":"2024-09-09T19:13:45.382592Z","shell.execute_reply.started":"2024-09-09T19:13:39.990436Z","shell.execute_reply":"2024-09-09T19:13:45.381712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras.models import load_model\n\n# Load the new CSV file with study descriptions\ndf = pd.read_csv('/kaggle/input/rsna-2024-lumbar-spine-degenerative-classification/test_series_descriptions.csv')\n\n# Define conditions and levels\nCONDITIONS = [\n    'spinal_canal_stenosis', \n    'left_neural_foraminal_narrowing', \n    'right_neural_foraminal_narrowing',\n    'left_subarticular_stenosis',\n    'right_subarticular_stenosis'\n]\nLEVELS = [\n    'l1_l2',\n    'l2_l3',\n    'l3_l4',\n    'l4_l5',\n    'l5_s1',\n]\n\n\ndef preprocess_image(img_path):\n    \"\"\"Preprocess an image for model prediction.\"\"\"\n    img = cv2.imread(img_path, cv2.IMREAD_COLOR)\n    if img is None:\n        return None\n    img_resized = cv2.resize(img, (320, 320))  # Resize\n    img_normalized = img_resized / 255.0  # Normalize\n    return img_normalized\n\ndef get_image_paths(directory):\n    \"\"\"Retrieve all PNG image paths from a directory.\"\"\"\n    image_paths = []\n    for root, _, files in os.walk(directory):\n        for file in files:\n            if file.lower().endswith('.png'):\n                image_paths.append(os.path.join(root, file))\n    return image_paths\n\ndef predict(img_paths):\n    \"\"\"Predict spinal condition severity for a list of images.\"\"\"\n    processed_images = [preprocess_image(path) for path in img_paths if preprocess_image(path) is not None]\n    if not processed_images:\n        return []\n    processed_images_array = np.array(processed_images)\n    predictions = model.predict(processed_images_array)\n    return predictions.tolist()  # Convert predictions to a list\n\n# Create a list to store the rows for the submission\nsubmission_data = []\n\n# Iterate through each unique study_id in the new CSV\nfor study_id in df[\"study_id\"].unique():\n    for condition in CONDITIONS:\n        for level in LEVELS:\n            row_id = \"_\".join([str(study_id), condition, level])\n            image_dir = f\"/kaggle/working/RSNA_test_images_png/{study_id}\"\n            \n            if not os.path.exists(image_dir):\n                continue\n\n            image_paths = get_image_paths(image_dir)\n            if not image_paths:\n                continue\n            \n            # Get predictions for each image in the directory\n            preds = predict(image_paths)\n            \n            if preds:\n                # Add predictions to the list for each image\n                for pred in preds:\n                    submission_data.append([row_id, *pred])\n            else:\n                # Default values if no predictions are available\n                submission_data.append([row_id, 0, 0, 0])\n\n# Create the submission DataFrame with the correct columns\nsubmission_df = pd.DataFrame(submission_data, columns=[\"row_id\", \"normal_mild\", \"moderate\", \"severe\"])\n\n# Save to CSV\nsubmission_df.to_csv('submission.csv', index=False)\n\nprint(\"Submission DataFrame preview:\")\nsubmission_df.head(20)","metadata":{"execution":{"iopub.status.busy":"2024-09-09T19:13:48.053360Z","iopub.execute_input":"2024-09-09T19:13:48.053753Z","iopub.status.idle":"2024-09-09T19:14:22.263102Z","shell.execute_reply.started":"2024-09-09T19:13:48.053716Z","shell.execute_reply":"2024-09-09T19:14:22.262177Z"},"trusted":true},"execution_count":null,"outputs":[]}]}